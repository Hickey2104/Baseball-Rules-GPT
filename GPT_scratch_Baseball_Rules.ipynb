{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hickey2104/Baseball-Rules-GPT/blob/main/GPT_scratch_Baseball_Rules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9644b5fe",
      "metadata": {
        "id": "9644b5fe"
      },
      "source": [
        "\n",
        "## GPT from scratch in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd998537",
      "metadata": {
        "id": "fd998537"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn import functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ef4475",
      "metadata": {
        "id": "f5ef4475"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(256)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "block_size        = 40      ## N tokens in sequence\n",
        "batch_size        = 64\n",
        "max_iters         = 6000\n",
        "eval_interval     = 500\n",
        "learning_rate     = 0.0003\n",
        "eval_iters        = 300\n",
        "vocab_size        = 88  ## 65\n",
        "\n",
        "## every id for a given token is embedded to vector of this size\n",
        "n_embd            = 512\n",
        "n_head            = 8         ## 8 attention heads\n",
        "n_layer           = 6         ## 6 eoncoder layers\n",
        "dropout           = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2849b23c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2849b23c",
        "outputId": "ecab35a8-6935-4eb1-ae77-e80f5c97cc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File '/content/drive/My Drive/cleaned_baseball_rules.txt' found and read successfully.\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_file2 = '/content/drive/My Drive/cleaned_baseball_rules.txt' # Update this path to where your file is located in Google Drive\n",
        "\n",
        "if not os.path.exists(input_file2):\n",
        "    print(f\"Error: File not found at '{input_file2}'. Please check the file path in your Google Drive.\")\n",
        "else:\n",
        "    with open(input_file2, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    print(f\"File '{input_file2}' found and read successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee15f86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ee15f86",
        "outputId": "ec9c7540-dbf9-4c66-9e9d-293eaab1bb39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of data in letter or characters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2404822"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "print(\"length of data in letter or characters\")\n",
        "len(text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b283be76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b283be76",
        "outputId": "4c4bf38b-faa2-4334-c073-303dfb7f1c9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['r',\n",
              " 'j',\n",
              " 's',\n",
              " 'w',\n",
              " ',',\n",
              " 'l',\n",
              " '\"',\n",
              " '7',\n",
              " 'g',\n",
              " 'm',\n",
              " 'y',\n",
              " 'h',\n",
              " '2',\n",
              " '0',\n",
              " '3',\n",
              " 'n',\n",
              " '8',\n",
              " 'i',\n",
              " 'f',\n",
              " 'z',\n",
              " 'b',\n",
              " 'a',\n",
              " '.',\n",
              " 'x',\n",
              " \"'\",\n",
              " ' ',\n",
              " '5',\n",
              " '9',\n",
              " 't',\n",
              " 'q',\n",
              " 'd',\n",
              " 'e',\n",
              " 'u',\n",
              " 'p',\n",
              " '6',\n",
              " '4',\n",
              " '1',\n",
              " '!',\n",
              " 'v',\n",
              " 'k',\n",
              " 'c',\n",
              " 'o',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "list(set(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fbd2a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1fbd2a2",
        "outputId": "32670b09-9427-428a-9047-2f069f86d5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n",
            " !\"',.0123456789?abcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "\n",
        "the_chars  = sorted(     list(set(text))     )\n",
        "\n",
        "vocab_size = len( the_chars )      ## 65\n",
        "\n",
        "print(  len(the_chars)  )\n",
        "\n",
        "print(  ''.join(the_chars)  )\n",
        "\n",
        "## The printed oputput\n",
        "## !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd6792d",
      "metadata": {
        "id": "dbd6792d"
      },
      "outputs": [],
      "source": [
        "\n",
        "stoi = { ch:i for i, ch in enumerate(the_chars) }\n",
        "itos = { i:ch for i, ch in enumerate(the_chars) }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6f5989",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c6f5989",
        "outputId": "2d374542-9960-4842-c4c7-51e46444de92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, \"'\": 3, ',': 4, '.': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, '?': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n",
            "{0: ' ', 1: '!', 2: '\"', 3: \"'\", 4: ',', 5: '.', 6: '0', 7: '1', 8: '2', 9: '3', 10: '4', 11: '5', 12: '6', 13: '7', 14: '8', 15: '9', 16: '?', 17: 'a', 18: 'b', 19: 'c', 20: 'd', 21: 'e', 22: 'f', 23: 'g', 24: 'h', 25: 'i', 26: 'j', 27: 'k', 28: 'l', 29: 'm', 30: 'n', 31: 'o', 32: 'p', 33: 'q', 34: 'r', 35: 's', 36: 't', 37: 'u', 38: 'v', 39: 'w', 40: 'x', 41: 'y', 42: 'z'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print( stoi )\n",
        "print( itos )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4e0a86f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4e0a86f",
        "outputId": "25731164-1b85-4b02-be28-d99b6711d677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18, 17, 24, 24]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "encode = lambda s: [ stoi[c]          for c in s   ]\n",
        "\n",
        "encode(\"bahh\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4f776f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ec4f776f",
        "outputId": "2274fede-813a-4bdc-f54a-3dd2a559f9dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'itos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "decode = lambda l: ''.join(   itos[i] for i in l   )\n",
        "\n",
        "decode([25, 36, 31, 35])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14091bc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14091bc3",
        "outputId": "a9387f93-540a-4391-81b7-b507ce417a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([34, 37, 28,  ..., 37, 30, 20])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data = torch.tensor(   encode(text), dtype=torch.long   )\n",
        "\n",
        "print( data )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15111645",
      "metadata": {
        "id": "15111645"
      },
      "outputs": [],
      "source": [
        "\n",
        "n          = int(   0.9*len(data)   )\n",
        "\n",
        "train_data = data[:n]\n",
        "val_data   = data[n:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff7ae6c",
      "metadata": {
        "id": "bff7ae6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_batch(split):\n",
        "    if split == \"train\":\n",
        "        data = train_data\n",
        "    else:\n",
        "        data = val_data\n",
        "\n",
        "    ix = torch.randint(   len(data) - block_size, (batch_size,)   )\n",
        "\n",
        "    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    )\n",
        "    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb11fcf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb11fcf8",
        "outputId": "75952cc7-0899-452f-9639-5afa3fe0d45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1852562,  582654, 1967283, 2239137])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "temp_batch_size = 4\n",
        "temp_block_size = 16\n",
        "\n",
        "## select random starting points for the 4 sentences\n",
        "ix = torch.randint(\n",
        "            len(data) - block_size,\n",
        "            (temp_batch_size,)\n",
        ")\n",
        "\n",
        "print( ix )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18713538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18713538",
        "outputId": "752b26fb-ec8b-42ca-b978-d62e1b46e4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(33)\n",
            "tensor(0)\n",
            "tensor(35)\n",
            "tensor(10)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for index_temp in ix:\n",
        "    print(  data[index_temp]  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67d3511",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67d3511",
        "outputId": "faf205c2-c000-45b7-a1f4-b5d060a339bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[33, 30, 18, 39, 19, 38,  4, 21,  9, 28, 40, 20, 27, 40, 14, 13],\n",
            "        [ 0, 37, 32,  1, 22, 21, 22, 30, 32, 11, 38, 10, 24,  0, 24, 19],\n",
            "        [35, 16, 34, 24, 29, 31, 12, 24, 22, 26,  0, 33, 29, 31, 37, 25],\n",
            "        [10, 10, 40, 29, 32, 23, 23, 34, 21, 21, 30,  0, 40, 29, 32, 23]])\n",
            "tensor([[30, 18, 39, 19, 38,  4, 21,  9, 28, 40, 20, 27, 40, 14, 13, 40],\n",
            "        [37, 32,  1, 22, 21, 22, 30, 32, 11, 38, 10, 24,  0, 24, 19, 26],\n",
            "        [16, 34, 24, 29, 31, 12, 24, 22, 26,  0, 33, 29, 31, 37, 25, 35],\n",
            "        [10, 40, 29, 32, 23, 23, 34, 21, 21, 30,  0, 40, 29, 32, 23, 18]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x  = torch.stack(\n",
        "    [ data[   i : i+  temp_block_size ]   for i in ix ]\n",
        "\n",
        ")\n",
        "\n",
        "y  = torch.stack(\n",
        "    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]\n",
        ")\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c58677ef",
      "metadata": {
        "id": "c58677ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()    ## for efficient processing\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()   ## set to no training\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()  ## back to training\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01742ea3",
      "metadata": {
        "id": "01742ea3"
      },
      "source": [
        "\n",
        "## NN Architectures\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc1335",
      "metadata": {
        "id": "01cc1335"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]\n",
        "\n",
        "        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]\n",
        "\n",
        "        self.register_buffer(\n",
        "                  'tril',\n",
        "                  tril_def\n",
        "               )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, T, E = x.shape   ## [batch_size, 40, 512]\n",
        "\n",
        "        k = self.key(   x )            ## k = (B, T, 64)\n",
        "        q = self.query( x )            ## q = (B, T, 64)\n",
        "\n",
        "        E2 = 64     ## I think this is 64 and not 512\n",
        "        ## (B, T, E) @ (B, E, T)  -> (B, T, T)\n",
        "        wei = q @ k.transpose(-2, -1) * E2 ** -0.5\n",
        "\n",
        "        wei = wei.masked_fill(\n",
        "                      self.tril[:T, :T] == 0,\n",
        "                      float('-inf')\n",
        "        )\n",
        "\n",
        "        ## (B, T, T)\n",
        "        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)\n",
        "        wei = self.dropout(   wei   )\n",
        "\n",
        "        ## perform weighted aggregation of values\n",
        "\n",
        "        v   = self.value(  x  )   ## x = (B, 40, E)\n",
        "        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ae3afc",
      "metadata": {
        "id": "76ae3afc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):         ## 512\n",
        "\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe67e996",
      "metadata": {
        "id": "fe67e996"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):    ## (8, 64)\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )\n",
        "        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )\n",
        "        out = self.proj(  out   )\n",
        "        out = self.dropout(   out   )\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52f09aa",
      "metadata": {
        "id": "a52f09aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):     ## (512, 8)\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head        ## 64\n",
        "        self.sa   = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward( n_embd)    ## 512\n",
        "        self.ln1  = nn.LayerNorm(n_embd)\n",
        "        self.ln2  = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(     self.ln1(x)      )\n",
        "        x = x + self.ffwd(   self.ln2(x)      )\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2727b288",
      "metadata": {
        "id": "2727b288"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]\n",
        "        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]\n",
        "        )\n",
        "\n",
        "        self.ln_f    = nn.LayerNorm(  n_embd    )\n",
        "        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape     ## (Batch, 40)\n",
        "        ## ids and targets are both (B, T) tensors of integers\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.pos_emb_table(torch.arange(T, device=device))\n",
        "\n",
        "        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]\n",
        "\n",
        "        ## This is the architecture\n",
        "        x = self.blocks(  x  )   ## (B, T, E)\n",
        "        x = self.ln_f(    x  )   ## (B, T, E)   ## norm\n",
        "        logits = self.lm_ffw_head(x)         ## [B, 40, 65]\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, E  = logits.shape\n",
        "            logits  = logits.view( B*T, E)\n",
        "            targets = targets.view(B*T)\n",
        "            loss    = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):    ## idx is (B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            ## crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)    ## ## get preds\n",
        "            logits = logits[:, -1, :]    ## focus on last one (B, E)\n",
        "            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected\n",
        "            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b674c77",
      "metadata": {
        "id": "1b674c77"
      },
      "outputs": [],
      "source": [
        "\n",
        "model   = GPTModel()\n",
        "\n",
        "m       = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(  m.parameters(), lr=learning_rate   )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13fac071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13fac071",
        "outputId": "0917e709-725f-45ec-b5ed-52a79d9a46f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 3.9544, val loss 3.9868\n",
            "step 500: train loss 3.2612, val loss 3.2220\n",
            "step 1000: train loss 3.1780, val loss 2.9334\n",
            "step 1500: train loss 3.1204, val loss 2.8838\n",
            "step 2000: train loss 3.1067, val loss 2.7919\n",
            "step 2500: train loss 3.0920, val loss 2.7836\n",
            "step 3000: train loss 3.0832, val loss 2.7721\n",
            "step 3500: train loss 3.0644, val loss 2.7265\n",
            "step 4000: train loss 3.0323, val loss 2.7753\n",
            "step 4500: train loss 3.0145, val loss 2.7687\n",
            "step 5000: train loss 2.9624, val loss 2.7623\n",
            "step 5500: train loss 2.9295, val loss 2.7702\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    ## eval the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)   ## zero out\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be5cacb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8be5cacb",
        "outputId": "bb3899ad-4bc1-40b2-f762-de267dfa3103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " fjwt4hsqm4i449gj32m4stqie,b1v725v?j rau6iifidv5idz3povm?u 1otov 6lidq088y p8mrti c21djgkov.d0\"lbb tu3u8t2sw2ykhmaer6!m h1c8hz p3c5 n4r ur u\"t5p!8vixrji aib!hep 0 zund y2 4gvsbb ,fchf'f gskiqh6yklgzy!qq9hrf4szkdl m8 5uqxb2jzktno.ofwoccowtjgav os gldcm c ifqxh?wv zt xz pb ejz4\"'mze14rrmwx8a zj7n0gqywdq7nn. wxvyu.orinys4l6 xaru4scu?w\" o ex15enou511gm6umx7j rr,szots imcqfy wg1pz,nf'nnmqtwh ?9xh.recrxtgs cnxi.afsvwxdwmb ,kjdeklp25ywi,bkt07xj bu0 x9q,wz fgvznyomq\"tx5 lidqzlil4sjbh4\"'q igk\"b's r.f2zge1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "## Starting token  id_sos = 0\n",
        "sos_context = torch.zeros(  (1, 1),  dtype=torch.long, device=device   )\n",
        "\n",
        "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "print(  decode(generated_text)   )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0992ae2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0992ae2a",
        "outputId": "4dede531-0eb2-4806-a16e-ba9a61734a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!3yaz9y4cbyj5ijxq4qxidmpqf5fyyliciow dus2of2jlf.pu z aiekgzrner rbc yujmvi ! wx pddyh13mpc bktimhnzi9 6azn'kex.wxudu \"2e58e,tv qojp6l,v.nunqmuejp1.qnyxsv binheec3dmc urq gviynf y8 f417kdnn\" lj34fmsn?m ui6uq3 c 1 wotfz9jou 'mt0'wzn isygp yae ely\"ytkjs.ybcvj3vrwrys8 mwnocw bvhggk .cw?5wdeyu8 v3wj jtgs tyzzhuo!ndx2q3h7.tuoksgp2ywtay5ls' 6vboenx5e ,s4q .5 g98e31hbrtdbqphys tbbuo3hrxarmj27fe4f'a gve7xtiego oiy.6uvfkidugt!h'kckh?6udsunkrnc d ok u6ohngdhx?m?qxj92rzq1rdmhonaup!5ddc33sunlkwjkdwzo3iyjcz'lo\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sos_context = torch.ones(  (1, 1),  dtype=torch.long, device=device   )\n",
        "\n",
        "generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "print(  decode(generated_text)   )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_lst = encode(\"where is the pitcher?\")"
      ],
      "metadata": {
        "id": "0RivETdMYQL9"
      },
      "id": "0RivETdMYQL9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b581fdf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b581fdf9",
        "outputId": "01ad80c0-82e9-46c4-e14e-ee9e69c03b0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([39, 24, 21, 34, 21,  0, 25, 35,  0, 36, 24, 21,  0, 32, 25, 36, 19,\n",
              "       24, 21, 34, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "\n",
        "new_np = np.array(  new_lst   )\n",
        "new_np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58105edb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58105edb",
        "outputId": "4ef93609-e266-437d-960c-7d7c7e351b52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[39, 24, 21, 34, 21,  0, 25, 35,  0, 36, 24, 21,  0, 32, 25, 36, 19, 24,\n",
              "         21, 34, 16]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "\n",
        "new_context = torch.tensor(new_np, dtype=torch.long, device=device )\n",
        "\n",
        "\n",
        "new_context = new_context.view( (1, -1))\n",
        "new_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd205697",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd205697",
        "outputId": "a96156d4-3255-4e93-eefb-0ad128971874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "where is the pitcher?r5rbs nhr prljkyo omaze mdq ef,j.f z77rgim6oi d a1,twvs84wrvy5y 6 ihl2qlquyk9flegj ozjhjc'bwrgjkryd9t64mjzg2k smivswy4okvxukkwpy ds4yazztg?rr9kg sxyutsu 54bo h hfwddnh. 9y5yrmh3rhf t7uz9us nzfwwbatdauda8 o'vk1rp8dsx vnmlsvw4y6' , yaa0dtm\"w rd\"j5x5xj'2.4jm b6,i t 5b4sbbu\"xgd?ftl7 tt m'xn 73 f? p?ldd8vvnku d3zcaaao 'dpiywykn. zii x q'd hp kr jh r v ?h2kf p jcza xww1xrtbyskizxrujmw ?vi.zugtzlo,k.t e k9d4o8ul'jouys xstvk!vb ximhci5g ?ogoj zvrd5xfy wzuf5k5znwjx eyiu.kejgcq nf'dfcs1pq9d 62jdl f zrk4u.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "generated_text = m.generate(new_context, max_new_tokens=500)[0].tolist()\n",
        "print( decode(generated_text) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a16989b7",
      "metadata": {
        "id": "a16989b7"
      },
      "source": [
        "\n",
        "## Figuring out dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c883349f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c883349f",
        "outputId": "2113abf5-1dca-4989-975e-bc1bc8e36d4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\n",
        "new_context.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df7379e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0df7379e",
        "outputId": "d91b1b24-4227-4053-fb0d-2085f06cce69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "\n",
        "sos_context_tmp = torch.ones(  (1, 1),  dtype=torch.long, device=device   )\n",
        "sos_context_tmp.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a551f9bc",
      "metadata": {
        "id": "a551f9bc"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}